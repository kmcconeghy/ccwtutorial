---
title: "Estimation"
bibliography: references.bib
---

```{r }
#| label: setup
#| echo: false
#| message: false
#| 
library(here)
library(purrr)

source(here('scripts', 'setup.R'), echo=F)
# Set seed for reproducibility
set.seed(42)

 #increase size for bootstrapping procedure
  options(future.globals.maxSize = 4000*1024^2) 

  grid.draw.ggsurvplot = function(x) {
    survminer:::print.ggsurvplot(x, newpage=F)
  }
  
dta_c_panel = readRDS(here('dta', 'dta_cloned_panel.Rds')) %>%
  dplyr::filter(model == 'ay')
```


## Data 

Example uses the cloned dataset panel generated in [Data](app_01_syndata.qmd).

```{r }
#| label: data
#| echo: false
#| message: false
#| 
glimpse(dta_c_panel)
```

The person- or clone-level data must be expanded to a longitudinal panel where each observation (row) is a period of follow-up.

## Estimation of censoring weights {#ipcwplr}  

::: callout-note
There is no consideration here to model training, causal DAGs or covariate selection. It is simply a toy example to show the procedure.
:::

### Probability of treatment initiation

Since the example treatment strategy focuses on whether or not treatment initiates, the censoring weights can be computed from a model on the *uncloned* dataset where the event is treatment, and time to treatment. 

This may be a little confusing, but since my dataset is already cloned (duplicated by assignment). I take the clones where `assign=0` from the `dta_c_panel` dataset. These are clones assigned to not receive treatment, so their censoring time is time to treatment start and can be used for the treatment model. We are estimating time to treatment, not outcome. The clone, `assign=0` is already set up for this but for other projects this step will have to be modified if the comparator is different. 

```{r }
#| label: est-treat-prob
#| warning: FALSE

dta_cens = dta_c_panel[dta_c_panel$assign==0, ]

# assign == 0
  d_glm_cwt_num = glm(treat ~ poly(time, 2, raw=T), data=dta_cens, family=binomial()) # <1>
  
  d_glm_cwt_den = glm(treat ~ poly(time, 2, raw=T) + X + X_t + poly(age, 2) + female, # <1>
                 data=dta_cens, family=binomial()) # <1>

  dta_c_panel$pr_cens_num = predict(d_glm_cwt_num, newdata = dta_c_panel, type='response') # <2>
  dta_c_panel$pr_cens_den = predict(d_glm_cwt_den, newdata = dta_c_panel, type='response') # <2>
```

1.  logit model, where outcome is treat event, and it is regressed on a polynomial for time, along with covariates `X`, `X_t`, `age` and `female`. Separate numerator/denominators model for the stabilized weights. 

2. For each person, I estimate the conditional probability of treatment initiation at each timepoint.


```{r }
#| label: est-treat-grace
#| warning: FALSE
#| 
  dta_cens_grace = dta_cens %>% # <1>
    dplyr::filter(time==12 & t_treat>=12) #<1>
  
  d_glm_grace_num = glm(treat ~ 1, data=dta_cens_grace, family=binomial()) # <2>
  
  d_glm_grace_den = glm(treat ~ X + X_t + poly(age, 2) + female, # <2>
                 data=dta_cens_grace, family=binomial()) # <2>
  
  dta_c_panel$pr_grace_num = predict(d_glm_grace_num, newdata = dta_c_panel, type='response') 
  dta_c_panel$pr_grace_den = predict(d_glm_grace_den, newdata = dta_c_panel, type='response') 
```

1.  For the assign=1 arm, where treatment is to be initiated by period 12, I select the subset that has not initiated treatment by the beginning of period 12. 

2. I estimate the conditional probability of treatment initiation in this subset, which will be the censoring weight for that arm. Those initiating before week 12, have weights of 1. 

::: callout-note
There is some controversy in this workflow. Some do it like here by modeling the censoring probability off of a person-unique (no clones) dataset with treatment times, but others do it directly in the cloned dataset with the outcome of "censoring" where that may mean treatment initiation or some other thing.[@gaber2024]

I am unsure which is better?!
:::

## Calculation of weights

This step is highly specific to a project and must be considered carefully. I have found this step is error-prone due to misunderstandings about what the treatment strategy entails, or if the data is setup incorrectly. I refer you to the [Weighting scheme](ccw_01_intro.qmd#sec-weightscheme) section for further discussion.

::: callout-note
I only show the procedure here, for full diagnostics to evaluate weighting and model specification see: [IPW diagnostics](ccw_04_diag.qmd#sec-ipwdiag)
:::

### Unstabilized weights  

```{r }
#| label: cpt-weights-us
  setDT(dta_c_panel)
  
  dta_c_panel[, ipw := fcase(
    assign==0, 1 / (1-pr_cens_den), # <1>
    assign==0 & censor==1, 0, # <2>
    assign==1 & censor==1, 0, # <2>
    assign==1 & time < 12, 1, # <3>
    assign==1 & time == 12  & t_treat  < 12, 1, # <4> 
    assign==1 & time == 12  & t_treat  >=12, 1 / (pr_grace_den), # <5> 
    assign==1 & time > 12, 1, # <6>
    assign==1 & censor==1, 0
  )]
```

1.  (assign=0); because the model is Pr(treat=1), the no treatment clones are assigned 1 - Pr(treat=1), or the cumulative probability of no vaccination ~ Probability of remaining uncensored.

2. If a clone is censored, I assigned weight=0. 

3. (assign=1) Clones cannot artificially censor prior to grace period

4. (assign=1) If treatment started prior to grace window ending, the clone cannot censor

5.  (assign=1) If a clone is treated in the final period, then the probability of remaining uncensored is the probability of initiating treatment in the final period.

6. (assign=1) Set post-grace period weights = 1 for all, since treatment must occur by period 12 and no artificial censoring happens after this point for `assign==1`

### Stabilized weights  

```{r }
#| label: cpt-weights-st
  dta_c_panel[, marg_c0  := 1-mean(censor), by = list(assign, time)] # <1>

  dta_c_panel[, marg_ipw := fcase(
    assign==0, (marg_c0) / (1-pr_cens_den), # <1>
    assign==0 & censor==1, 0, # <2>
    assign==1 & censor==1, 0, # <2>
    assign==1 & time < 12, 1, # <3>
    assign==1 & time == 12  & t_treat  < 12, 1, # <4> 
    assign==1 & time == 12  & t_treat  >=12, marg_c0 / (pr_grace_den), # <5> 
    assign==1 & time > 12, 1, # <6>
    assign==1 & censor==1, 0
  )]
```

1.  Compute the mean by period and assignment group.  

2.  Replace the numerator in the ipw calculation with the marginal probability.

### Final weights

```{r }
  dta_c_panel[, `:=`(ipw = cumprod(ipw), 
                     marg_ipw = cumprod(marg_ipw)), 
               by=list(id, assign)] 
```

Compute the cumulative product within person-clone to reach final IPCW.  

::: callout-note
Be very careful with IPW truncation with this design. If the probability of treatment is very low, then those treated at the end of the grace period will have very large weights. If you truncate at 99% for example, it could mostly just truncate the weights of those treated at the end of the grace period, and this could severely bias estimates. These persons are meant to account for all those being artificially censored in the treatment group for non-treatment and so will likely have large weights by design. 
:::

## Outcome model  

### PLR model for cumulative incidences  

With the estimated weights, it is simple to generate weighted cumulative incidences:

```{r }
#| label: est-plr-wt
#| warning: FALSE  
  d_glm_pe_1 = glm(event==0 ~ poly(time, 2, raw=T), # <1>
                   data=dta_c_panel[dta_c_panel$assign==1, ], # <1>
                   family=binomial(), weights = ipw) # <1>
  # <1>
  d_glm_pe_0 = glm(event==0 ~ poly(time, 2, raw=T), # <1>
                   data=dta_c_panel[dta_c_panel$assign==0, ], # <1>
                     family=binomial(), weights = ipw) # <1>
  
  dta_c_panel$pr_1 = predict(d_glm_pe_1, newdata = dta_c_panel, # <2>
                             type='response') # <2>
  dta_c_panel$pr_0 = predict(d_glm_pe_0, newdata = dta_c_panel, # <2>
                             type='response') # <2>
```

1.  Estimate probability of the event for each assignment group separately. This isn't necessary but its good practice, and adjusting for other covariates may give different results as well. Note the `weights = ipw` argument. R `glm()` will generate a warning message because the weighted counts are "non-integer", but this is expected and not a problem.
2.  Assign conditional probabilities for event to each person-clone.

### Estimate cumulative incidences  

```{r }
#| label: survprob
#| 
  dta_c_panel[, `:=`(pr_cum_1 = cumprod(pr_1)), by=list(id, assign)] # <1>
  dta_c_panel[, `:=`(pr_cum_0 = cumprod(pr_0)), by=list(id, assign)] # <1>
  
  d_plrwt_est = dta_c_panel %>% # <2>
    group_by(time) %>% # <2>
    summarize(pr_ev_1 = mean(1-pr_cum_1),
              pr_ev_0 = mean(1-pr_cum_0), 
              .groups = 'drop') %>% # <2>
    ungroup %>% # <2>
    mutate(cid = pr_ev_1 - pr_ev_0, # <2>
           cir = pr_ev_1 / pr_ev_0) # <2>
```

1.  To estimate the cumulative event-free survival (1 - P(S) for incidence) you take the cumulative product within person-clone. 
2.  Summarize across group, time. I will generally compute both the risk difference `cid` and relative differences `cir`.

## Summarize Results  

```{r }
#| label: est-plr-stabwt
#| warning: FALSE  
#| echo: false
  d_glm_pe_1 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==1, ],
                   family=binomial(), weights = marg_ipw) 
  
  d_glm_pe_0 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==0, ], 
                     family=binomial(), weights = marg_ipw) 
  
  dta_c_panel$pr_1 = predict(d_glm_pe_1, newdata = dta_c_panel, 
                             type='response') 
  dta_c_panel$pr_0 = predict(d_glm_pe_0, newdata = dta_c_panel, 
                             type='response') 
  
  dta_c_panel[, `:=`(pr_cum_1 = cumprod(pr_1)), by=list(id, assign)] 
  dta_c_panel[, `:=`(pr_cum_0 = cumprod(pr_0)), by=list(id, assign)] 
  
  d_plrstabwt_est = dta_c_panel %>% 
    group_by(time) %>% 
    summarize(pr_ev_1 = mean(1-pr_cum_1),
              pr_ev_0 = mean(1-pr_cum_0), 
              .groups = 'drop') %>% 
    ungroup %>% 
    mutate(cid = pr_ev_1 - pr_ev_0, 
           cir = pr_ev_1 / pr_ev_0) 
  
  d_glm_pe_1 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==1, ], 
                   family=binomial()) 
  
  d_glm_pe_0 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==0, ], 
                     family=binomial()) 
  
  dta_c_panel$pr_1 = predict(d_glm_pe_1, newdata = dta_c_panel, 
                             type='response') 
  dta_c_panel$pr_0 = predict(d_glm_pe_0, newdata = dta_c_panel, 
                             type='response') 
  
  dta_c_panel[, `:=`(pr_cum_1 = cumprod(pr_1)), by=list(id, assign)] 
  dta_c_panel[, `:=`(pr_cum_0 = cumprod(pr_0)), by=list(id, assign)] 
  
  d_plrnv_est = dta_c_panel %>% 
    group_by(time) %>% 
    summarize(pr_ev_1 = mean(1-pr_cum_1),
              pr_ev_0 = mean(1-pr_cum_0), 
              .groups = 'drop') %>% 
    ungroup %>% 
    mutate(cid = pr_ev_1 - pr_ev_0, 
           cir = pr_ev_1 / pr_ev_0)
```


### Figure 

```{r }
#| label: gg-plr-weighted
#| fig-cap: Weighted PLR Analysis
#| fig-cap-location: top
#| echo: false
#| eval: true
    d_gg_ci = d_plrwt_est %>%
      pivot_longer(cols = c(pr_ev_0, pr_ev_1), names_to = 'Assignment', values_to = 'pr_ev') %>%
      ggplot(aes(x=time, y = pr_ev, color = Assignment)) +
      geom_line(aes(linetype=Assignment), linewidth=1.2) +
      scale_color_manual(labels = c('Assign=0', 'Assign=1'), values = cbbPalette) +
      scale_linetype_manual(labels = c('Assign=0', 'Assign=1'), values = c(1, 2)) +
      scale_x_continuous(breaks = seq(0, 60, 6),
                         limits = c(0, 60)) +
      theme_bw() +
      labs(x = 'Follow-up', y = 'Cumulative incidence')
    
    d_gg_ci
```

The results can be easily depicted in a standard graph like any survival analysis. You could  also combine the lineplot with a table of the unweighted or weighted person and event counts at each point of follow-up like many do in a Kaplan-Meier analysis. 

### Table  

```{r }
#| label: tab-plr-result
#| tab-cap-location: top
#| echo: false
#| eval: true

d_all_est = 
  bind_rows(
    select(d_plrnv_est, time, pr_ev_1, pr_ev_0, cid, cir) %>%
      mutate(Model = 'Naive'),
    select(d_plrwt_est, time, pr_ev_1, pr_ev_0, cid, cir) %>%
      mutate(Model = 'IPCW'),
    select(d_plrstabwt_est, time, pr_ev_1, pr_ev_0, cid, cir) %>%
      mutate(Model = 'Stabilized')
  ) %>%
  dplyr::filter(time %in% c(6, 12, 36, 60))

t_summ_all = kables(caption = 'A -> Y, X -> {A, Y}',
  list(d_all_est %>%
         pivot_wider(., id_cols = time, names_from = Model, values_from = cid) %>%
         kable(digits=3, align = 'c') %>%
         kable_styling() %>%
         add_header_above(., c("Risk Differences" = 4)),
       d_all_est %>%
         pivot_wider(., id_cols = time, names_from = Model, values_from = cir) %>%
         kable(digits=3, align = 'c') %>%
         kable_styling() %>%
         add_header_above(., c("Relative Risks" = 4))
       )
  )

t_summ_all
```

```{r }
#| label: tab-plr-result-xy
#| tab-cap-location: top
#| warning: false
#| echo: false
#| eval: true

dta_c_panel = readRDS(here('dta', 'dta_cloned_panel.Rds')) %>%
  dplyr::filter(model == 'xy')

dta_cens = dta_c_panel[dta_c_panel$assign==0, ]

# assign == 0
  d_glm_cwt_num = glm(treat ~ poly(time, 2, raw=T), data=dta_cens, family=binomial()) # <1>
  
  d_glm_cwt_den = glm(treat ~ poly(time, 2, raw=T) + X + X_t + poly(age, 2) + female, # <1>
                 data=dta_cens, family=binomial()) # <1>

  dta_c_panel$pr_cens_num = predict(d_glm_cwt_num, newdata = dta_c_panel, type='response') # <2>
  dta_c_panel$pr_cens_den = predict(d_glm_cwt_den, newdata = dta_c_panel, type='response') # <2>
  
dta_cens_grace = dta_cens %>% # <1>
    dplyr::filter(time==12 & t_treat>=12) #<1>
  
  d_glm_grace_num = glm(treat ~ 1, data=dta_cens_grace, family=binomial()) # <2>
  
  d_glm_grace_den = glm(treat ~ X + X_t + poly(age, 2) + female, # <2>
                 data=dta_cens_grace, family=binomial()) # <2>
  
  dta_c_panel$pr_grace_num = predict(d_glm_grace_num, newdata = dta_c_panel, type='response') 
  dta_c_panel$pr_grace_den = predict(d_glm_grace_den, newdata = dta_c_panel, type='response') 
  
setDT(dta_c_panel)
  
  dta_c_panel[, ipw := fcase(
    assign==0, 1 / (1-pr_cens_den), # <1>
    assign==0 & censor==1, 0, # <2>
    assign==1 & censor==1, 0, # <2>
    assign==1 & time < 12, 1, # <3>
    assign==1 & time == 12  & t_treat  < 12, 1, # <4> 
    assign==1 & time == 12  & t_treat  >=12, 1 / (pr_grace_den), # <5> 
    assign==1 & time > 12, 1, # <6>
    assign==1 & censor==1, 0
  )]
  
dta_c_panel[, marg_c0  := 1-mean(censor), by = list(assign, time)] # <1>

dta_c_panel[, marg_ipw := fcase(
    assign==0, (marg_c0) / (1-pr_cens_den), # <1>
    assign==0 & censor==1, 0, # <2>
    assign==1 & censor==1, 0, # <2>
    assign==1 & time < 12, 1, # <3>
    assign==1 & time == 12  & t_treat  < 12, 1, # <4> 
    assign==1 & time == 12  & t_treat  >=12, marg_c0 / (pr_grace_den), # <5> 
    assign==1 & time > 12, 1, # <6>
    assign==1 & censor==1, 0
  )]
  
  dta_c_panel[, `:=`(ipw = cumprod(ipw), 
                     marg_ipw = cumprod(marg_ipw)), 
               by=list(id, assign)] 

  d_glm_pe_1 = glm(event==0 ~ poly(time, 2, raw=T), # <1>
                   data=dta_c_panel[dta_c_panel$assign==1, ], # <1>
                   family=binomial(), weights = ipw) # <1>
  # <1>
  d_glm_pe_0 = glm(event==0 ~ poly(time, 2, raw=T), # <1>
                   data=dta_c_panel[dta_c_panel$assign==0, ], # <1>
                     family=binomial(), weights = ipw) # <1>
  
  dta_c_panel$pr_1 = predict(d_glm_pe_1, newdata = dta_c_panel, # <2>
                             type='response') # <2>
  dta_c_panel$pr_0 = predict(d_glm_pe_0, newdata = dta_c_panel, # <2>
                             type='response') # <2>
  
  dta_c_panel[, `:=`(pr_cum_1 = cumprod(pr_1)), by=list(id, assign)] # <1>
  dta_c_panel[, `:=`(pr_cum_0 = cumprod(pr_0)), by=list(id, assign)] # <1>
  
  d_plrwt_est = dta_c_panel %>% # <2>
    group_by(time) %>% # <2>
    summarize(pr_ev_1 = mean(1-pr_cum_1),
              pr_ev_0 = mean(1-pr_cum_0), 
              .groups = 'drop') %>% # <2>
    ungroup %>% # <2>
    mutate(cid = pr_ev_1 - pr_ev_0, # <2>
           cir = pr_ev_1 / pr_ev_0) # <2>

  d_glm_pe_1 = glm(event==0 ~ poly(time, 2, raw=T), 
                     data=dta_c_panel[dta_c_panel$assign==1, ],
                     family=binomial(), weights = marg_ipw) 
  
  d_glm_pe_0 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==0, ], 
                     family=binomial(), weights = marg_ipw) 
  
  dta_c_panel$pr_1 = predict(d_glm_pe_1, newdata = dta_c_panel, 
                             type='response') 
  dta_c_panel$pr_0 = predict(d_glm_pe_0, newdata = dta_c_panel, 
                             type='response') 
  
  dta_c_panel[, `:=`(pr_cum_1 = cumprod(pr_1)), by=list(id, assign)] 
  dta_c_panel[, `:=`(pr_cum_0 = cumprod(pr_0)), by=list(id, assign)] 
  
  d_plrstabwt_est = dta_c_panel %>% 
    group_by(time) %>% 
    summarize(pr_ev_1 = mean(1-pr_cum_1),
              pr_ev_0 = mean(1-pr_cum_0), 
              .groups = 'drop') %>% 
    ungroup %>% 
    mutate(cid = pr_ev_1 - pr_ev_0, 
           cir = pr_ev_1 / pr_ev_0) 
  
  d_glm_pe_1 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==1, ], 
                   family=binomial()) 
  
  d_glm_pe_0 = glm(event==0 ~ poly(time, 2, raw=T), 
                   data=dta_c_panel[dta_c_panel$assign==0, ], 
                     family=binomial()) 
  
  dta_c_panel$pr_1 = predict(d_glm_pe_1, newdata = dta_c_panel, 
                             type='response') 
  dta_c_panel$pr_0 = predict(d_glm_pe_0, newdata = dta_c_panel, 
                             type='response') 
  
  dta_c_panel[, `:=`(pr_cum_1 = cumprod(pr_1)), by=list(id, assign)] 
  dta_c_panel[, `:=`(pr_cum_0 = cumprod(pr_0)), by=list(id, assign)] 
  
  d_plrnv_est = dta_c_panel %>% 
    group_by(time) %>% 
    summarize(pr_ev_1 = mean(1-pr_cum_1),
              pr_ev_0 = mean(1-pr_cum_0), 
              .groups = 'drop') %>% 
    ungroup %>% 
    mutate(cid = pr_ev_1 - pr_ev_0, 
           cir = pr_ev_1 / pr_ev_0)
  
d_all_est = 
  bind_rows(
    select(d_plrnv_est, time, pr_ev_1, pr_ev_0, cid, cir) %>%
      mutate(Model = 'Naive'),
    select(d_plrwt_est, time, pr_ev_1, pr_ev_0, cid, cir) %>%
      mutate(Model = 'IPCW'),
    select(d_plrstabwt_est, time, pr_ev_1, pr_ev_0, cid, cir) %>%
      mutate(Model = 'Stabilized')
  ) %>%
  dplyr::filter(time %in% c(6, 12, 36, 60))

t_summ_all = kables(caption = 'X -> A, Y, A does not cause Y',
  list(d_all_est %>%
         pivot_wider(., id_cols = time, names_from = Model, values_from = cid) %>%
         kable(digits=3, align = 'c') %>%
         kable_styling() %>%
         add_header_above(., c("Risk Differences" = 4)),
       d_all_est %>%
         pivot_wider(., id_cols = time, names_from = Model, values_from = cir) %>%
         kable(digits=3, align = 'c') %>%
         kable_styling() %>%
         add_header_above(., c("Relative Risks" = 4))
       )
  )

t_summ_all
```

# References

::: {#refs}
:::
